{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c47f41-9f7e-404d-8598-a4df6a3d7273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb7e9af-4d44-48e3-823b-9e846a915b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_cosine(t, T, s):\n",
    "  return math.cos((t/T + s)/(1 + s))**2\n",
    "\n",
    "def a_t(t,T,s):\n",
    "  return f_cosine(t, T, s)/f_cosine(0, T, s)\n",
    "\n",
    "def beta_t(t, T, s):\n",
    "  return np.clip(1 - a_t(t, T, s)/a_t(t-1, T, s), a_min=-1, a_max=0.999)\n",
    "\n",
    "def cosine_schedule(T, s=0.001):\n",
    "  return [beta_t(t, T, s) for t in range(1,T+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcfdc816-8d28-4fdd-b45e-3eb007ed4929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class NoiseTransform:\n",
    "  def __init__(self, schedule):\n",
    "    self.schedule = schedule\n",
    "\n",
    "  def __call__(self, img):\n",
    "    T = len(self.schedule)\n",
    "    t = np.random.randint(low=1, high=T)\n",
    "    alphas_prod = np.prod((1 - np.array(self.schedule))[:t])\n",
    "    #print(alphas_prod)\n",
    "    e = torch.normal(mean=0, std=1, size=img.shape)\n",
    "    img_with_noise = (img * math.sqrt(alphas_prod) + e * math.sqrt(1-alphas_prod)).clip(min=0, max=1)\n",
    "    return (img_with_noise, t, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5dc748-267e-4a24-929e-94db28d52ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform_with_noise = transforms.Compose([\n",
    "    transforms.Resize(size=(28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    NoiseTransform(cosine_schedule(100))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1d7886-8822-4555-8de1-bf6bf8ca434a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset MNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=(28, 28), interpolation=bilinear, max_size=None, antialias=True)\n",
       "                ToTensor()\n",
       "                <__main__.NoiseTransform object at 0x000002313BF95E50>\n",
       "            ),\n",
       " Dataset MNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=(28, 28), interpolation=bilinear, max_size=None, antialias=True)\n",
       "                ToTensor()\n",
       "                <__main__.NoiseTransform object at 0x000002313BF95E50>\n",
       "            ))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=image_transform_with_noise,\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=image_transform_with_noise,\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf62bff-fd87-42b4-a642-bd6338e072a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x2315cd1a690>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x2315c756390>,\n",
       " 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              num_workers=NUM_WORKERS,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              num_workers=NUM_WORKERS,\n",
    "                              shuffle=False)\n",
    "\n",
    "train_dataloader, test_dataloader, NUM_WORKERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61a31bac-bee5-4e55-b030-32599d376fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "  def __init__(self, n_dim):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "\n",
    "    self.n_dim = n_dim\n",
    "\n",
    "  def forward(self, x):\n",
    "    x_shape = x.shape\n",
    "    x_flat = x.reshape(-1)\n",
    "    out = torch.zeros(size=(*x_flat.shape, self.n_dim))\n",
    "    for idx, elem in enumerate(x_flat):\n",
    "      out[idx, :] = self.__positional_encoding(elem, self.n_dim)\n",
    "\n",
    "    out = out.reshape((*x_shape, self.n_dim))\n",
    "    return out\n",
    "\n",
    "  def __positional_encoding(self, pos, ndim):\n",
    "    return torch.tensor([ (math.sin(pos/10000**(int(i/2) / ndim )) if i%2 == 0 else  math.cos(pos/10000**(int(i/2) / ndim )))  for i in range(ndim)]).type(torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1785bc33-7d87-4ec0-9b0a-d71607449ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "  def __init__(self, in_ch, out_ch):\n",
    "    super(DoubleConv, self).__init__()\n",
    "    self.conv = nn.Sequential(\n",
    "        nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_ch),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(out_ch),\n",
    "        nn.ReLU(inplace=True),\n",
    "      )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87e7ce9d-999c-4a82-a9c9-801120a91aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownLayer(nn.Module):\n",
    "  def __init__(self, in_ch, out_ch, img_height, img_width, n_dim):\n",
    "    super(DownLayer, self).__init__()\n",
    "\n",
    "    self.img_width = img_width\n",
    "    self.img_height = img_height\n",
    "    self.out_ch = out_ch\n",
    "\n",
    "    self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "    self.conv = DoubleConv(in_ch, out_ch)\n",
    "\n",
    "    self.silu = nn.SiLU()\n",
    "    self.lin_pe = nn.Linear(n_dim, out_ch * (img_height // 2) * (img_width // 2))\n",
    "\n",
    "  def forward(self, x, pet_s):\n",
    "    x = self.max_pool(x)\n",
    "    x = self.conv(x)\n",
    "\n",
    "    pet_s_1 = self.silu(pet_s)\n",
    "    pet_s_2 = self.lin_pe(pet_s_1)\n",
    "    pet_s_3 = pet_s_2.view(-1, self.out_ch, self.img_height // 2, self.img_width // 2)\n",
    "\n",
    "    #print(x.shape, pet_s.shape)\n",
    "    x = x + pet_s_3\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b510179-9b24-4862-9296-1ab2be351597",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Up(nn.Module):\n",
    "  def __init__(self, in_ch, out_ch):\n",
    "    super(Up, self).__init__()\n",
    "\n",
    "    self.up_scale = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)\n",
    "\n",
    "  def forward(self, x1, x2):\n",
    "    x2 = self.up_scale(x2)\n",
    "\n",
    "    diffY = x1.size()[2] - x2.size()[2]\n",
    "    diffX = x1.size()[3] - x2.size()[3]\n",
    "\n",
    "    x2 = F.pad(x2, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2 ])\n",
    "\n",
    "    x = torch.cat([x1,x2], dim=1)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95f5fb19-e34b-4f62-9c99-2e4e68ae7a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpLayer(nn.Module):\n",
    "  def __init__(self, in_ch, out_ch, img_height, img_width, n_dim):\n",
    "    super(UpLayer, self).__init__()\n",
    "\n",
    "    self.img_width = img_width\n",
    "    self.img_height = img_height\n",
    "    self.out_ch = out_ch\n",
    "\n",
    "    self.up = Up(in_ch, out_ch)\n",
    "    self.conv = DoubleConv(in_ch, out_ch)\n",
    "\n",
    "    self.silu = nn.SiLU()\n",
    "    self.lin_pe = nn.Linear(n_dim, out_ch * (img_height * 2) * (img_width * 2))\n",
    "\n",
    "  def forward(self, x1, x2, pet_s):\n",
    "    a = self.up(x1, x2)\n",
    "    x = self.conv(a)\n",
    "\n",
    "    pet_s_1 = self.silu(pet_s)\n",
    "    pet_s_2 = self.lin_pe(pet_s_1)\n",
    "    pet_s_3 = pet_s_2.view(-1, self.out_ch, self.img_height * 2, self.img_width * 2)\n",
    "\n",
    "    #print(x.shape, pet_s.shape)\n",
    "    x = x + pet_s_3\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e336f8b-1b18-45c1-8020-0f1fdc36e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionBlock(nn.Module):\n",
    "  def __init__(self, in_ch, num_heads):\n",
    "    super(SelfAttentionBlock, self).__init__()\n",
    "    \n",
    "    self.layer_norm_mha = nn.LayerNorm([in_ch])\n",
    "\n",
    "    self.mha = nn.MultiheadAttention(embed_dim=in_ch, num_heads=num_heads)\n",
    "\n",
    "    self.layer_norm = nn.LayerNorm([in_ch])\n",
    "    self.linear_1 = nn.Linear(in_ch, in_ch)\n",
    "    self.gelu = nn.GELU()\n",
    "    self.linear_2 = nn.Linear(in_ch, in_ch)\n",
    "\n",
    "  def forward(self, x: torch.Tensor):\n",
    "\n",
    "    x_shape = x.shape\n",
    "\n",
    "    x = x.flatten(start_dim=-2, end_dim=-1).permute(0, 2, 1)\n",
    "\n",
    "    x1 = self.layer_norm_mha(x)\n",
    "    x2, _ = self.mha(x1, x1, x1) \n",
    "\n",
    "    x3 = x + x2\n",
    "\n",
    "    x3 = self.layer_norm(x3)\n",
    "    x3 = self.linear_1(x3)\n",
    "    x3 = self.gelu(x3)\n",
    "    x3 = self.linear_2(x3)\n",
    "\n",
    "    x4 = x2 + x3\n",
    "\n",
    "    x4 = x4.permute(0,2,1).reshape(-1, x_shape[-3],  x_shape[-2], x_shape[-1])\n",
    "\n",
    "    return x4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a61e268-42fe-425e-a10a-06290d532fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(UNet, self).__init__()\n",
    "\n",
    "    self.pos_enc = PositionalEncoding(50)\n",
    "\n",
    "    self.doubleconv = DoubleConv(1,32)\n",
    "    self.down1 = DownLayer(32,64,28,28,50)\n",
    "    self.down1_attention = SelfAttentionBlock(64, 4)\n",
    "    self.down2 = DownLayer(64,128,14,14,50)\n",
    "    self.down2_attention = SelfAttentionBlock(128, 4)\n",
    "    self.middle_conv = DoubleConv(128, 128)\n",
    "    self.up1 = UpLayer(128,64, 7, 7, 50)\n",
    "    self.up1_attention = SelfAttentionBlock(64, 4)\n",
    "    self.up2 = UpLayer(64,32, 14, 14, 50)\n",
    "    self.up2_attention = SelfAttentionBlock(32, 4)\n",
    "    self.last_conv = nn.Conv2d(32, 1, 1)\n",
    "\n",
    "  def forward(self, x, t):\n",
    "    t = self.pos_enc(t)\n",
    "\n",
    "    x1 = self.doubleconv(x)\n",
    "    x2 = self.down1(x1, t)\n",
    "    x2 = self.down1_attention(x2)\n",
    "    x3 = self.down2(x2, t)\n",
    "    x3 = self.down2_attention(x3)\n",
    "    x3 = self.middle_conv(x3)\n",
    "    x1_up = self.up1(x2, x3, t)\n",
    "    x1_up = self.up1_attention(x1_up)\n",
    "    x2_up = self.up2(x1, x1_up, t)\n",
    "    x2_up = self.up2_attention(x2_up)\n",
    "    output = self.last_conv(x2_up)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a7cc8d4-216e-417d-8067-c84491d0dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d0ceb9b-6040-4f05-be13-456c8d12dd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(),\n",
    "                            lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97a4f17e-a8a9-4f7a-8a9f-247d90c532af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [10:06<00:00,  3.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 313/313 [00:41<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.22708 | Test loss: 0.22939\n",
      "\n",
      "Epoch: 1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [10:34<00:00,  2.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 313/313 [00:41<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.22614 | Test loss: 0.40983\n",
      "\n",
      "Epoch: 2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [10:48<00:00,  2.89it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 313/313 [00:42<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.22522 | Test loss: 0.33875\n",
      "\n",
      "Epoch: 3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [10:11<00:00,  3.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 313/313 [00:39<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.22484 | Test loss: 0.23752\n",
      "\n",
      "Epoch: 4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [10:04<00:00,  3.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 313/313 [00:39<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.22374 | Test loss: 0.22470\n",
      "\n",
      "Epoch: 5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [10:04<00:00,  3.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 313/313 [00:39<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.22321 | Test loss: 0.22470\n",
      "\n",
      "Epoch: 6\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [10:04<00:00,  3.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 313/313 [00:39<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.22307 | Test loss: 0.22380\n",
      "\n",
      "Epoch: 7\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [10:04<00:00,  3.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 313/313 [00:39<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.22255 | Test loss: 0.22226\n",
      "\n",
      "Epoch: 8\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [10:04<00:00,  3.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 313/313 [00:39<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.22203 | Test loss: 0.22245\n",
      "\n",
      "Epoch: 9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [10:15<00:00,  3.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 313/313 [00:44<00:00,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss: 0.22129 | Test loss: 0.22536\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  print(f\"Epoch: {epoch}\\n----------\")\n",
    "\n",
    "  model.train()\n",
    "  train_loss = 0\n",
    "  for (X, t, e), _ in tqdm(train_dataloader):\n",
    "\n",
    "    e_pred = model(X, t)\n",
    "\n",
    "    loss = loss_fn(e_pred,e)\n",
    "    train_loss += loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "      \n",
    "  train_loss /= len(train_dataloader)\n",
    "\n",
    "  test_loss = 0\n",
    "  model.eval()\n",
    "  with torch.inference_mode():\n",
    "    for (X_test, t_test, e_test), _ in tqdm(test_dataloader):\n",
    "      test_pred = model(X_test, t_test)\n",
    "\n",
    "      test_loss += loss_fn(test_pred, e_test)\n",
    "\n",
    "    test_loss /= len(test_dataloader)\n",
    "\n",
    "  print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f7b6165-b5e3-485a-97e3-a0ff44dbf760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (pos_enc): PositionalEncoding()\n",
       "  (doubleconv): DoubleConv(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): DownLayer(\n",
       "    (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (silu): SiLU()\n",
       "    (lin_pe): Linear(in_features=20, out_features=6272, bias=True)\n",
       "  )\n",
       "  (down1_attention): SelfAttentionBlock(\n",
       "    (layer_norm_mha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (mha): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (linear_1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (linear_2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (down2): DownLayer(\n",
       "    (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (silu): SiLU()\n",
       "    (lin_pe): Linear(in_features=20, out_features=3136, bias=True)\n",
       "  )\n",
       "  (down2_attention): SelfAttentionBlock(\n",
       "    (layer_norm_mha): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (mha): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (linear_1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (linear_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (middle_conv): DoubleConv(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up1): UpLayer(\n",
       "    (up): Up(\n",
       "      (up_scale): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (conv): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (silu): SiLU()\n",
       "    (lin_pe): Linear(in_features=20, out_features=6272, bias=True)\n",
       "  )\n",
       "  (up1_attention): SelfAttentionBlock(\n",
       "    (layer_norm_mha): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (mha): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (linear_1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (linear_2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (up2): UpLayer(\n",
       "    (up): Up(\n",
       "      (up_scale): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (conv): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (silu): SiLU()\n",
       "    (lin_pe): Linear(in_features=20, out_features=12544, bias=True)\n",
       "  )\n",
       "  (up2_attention): SelfAttentionBlock(\n",
       "    (layer_norm_mha): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "    (mha): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "    )\n",
       "    (layer_norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "    (linear_1): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (gelu): GELU(approximate='none')\n",
       "    (linear_2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       "  (last_conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0f0c52-60be-418e-8e98-9e1fd85f7455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
